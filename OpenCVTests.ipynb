{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fbfa21-f104-4d37-873c-d0539a62f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda5888-a6a6-4b2e-8110-d3601b73ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./')\n",
    "print(os.getcwd())\n",
    "os.path.exists('licplt.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2342a-44c5-4e73-a44f-08a54579310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./licplt.jpg') #, cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf62ff-7ebf-4409-b805-ae6879e409b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = img.copy()\n",
    "template = cv.imread('template.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert template is not None, \"file could not be read, check with os.path.exists()\"\n",
    "w, h = template.shape[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e94fb-1289-48cd-9d63-726e92f95a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    " 'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    " \n",
    "for meth in methods:\n",
    " img = img2.copy()\n",
    " method = eval(meth)\n",
    " \n",
    " # Apply template Matching\n",
    " res = cv.matchTemplate(img,template,method)\n",
    " min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    " \n",
    " # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    " if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    " top_left = min_loc\n",
    " else:\n",
    " top_left = max_loc\n",
    " bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    " \n",
    " cv.rectangle(img,top_left, bottom_right, 255, 2)\n",
    " \n",
    " plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    " plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    " plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    " plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    " plt.suptitle(meth)\n",
    " \n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d0845-5b83-4140-9205-5f8bd1c09e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767e010-6548-4747-9e3d-f0557aaea161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the YOLO model (YOLOv3)\n",
    "net = cv2.dnn.readNetFromDarknet('./yolov3.cfg', './yolov3.weights')\n",
    "\n",
    "# Load the COCO class names (you can replace this with your own custom classes)\n",
    "with open('./coco.names') as f:\n",
    "    classes = f.read().strip().split('\\n')\n",
    "\n",
    "# Set the confidence threshold (to filter weak detections)\n",
    "confidence_thresh = 0.5\n",
    "\n",
    "# Load an image\n",
    "image_path = './licplt.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Create a blob from the image\n",
    "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "# Set the input to the network\n",
    "net.setInput(blob)\n",
    "\n",
    "# Get the output layer names\n",
    "output_layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "# Forward pass through the network\n",
    "outputs = net.forward(output_layer_names)\n",
    "\n",
    "# Process the detections\n",
    "for output in outputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "\n",
    "        if confidence > confidence_thresh:\n",
    "            # Get bounding box coordinates\n",
    "            box = detection[:4] * np.array([image.shape[1], image.shape[0], image.shape[1], image.shape[0]])\n",
    "            (x, y, w, h) = box.astype(int)\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            color = (0, 255, 0)  # Green color\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(image, classes[class_id], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('YOLO Object Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff6e55-5aa5-4c26-8845-8ce3deb0ac42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d0c0d-e6db-40f8-8b0d-d312eb3e2fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
